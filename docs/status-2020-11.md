# Monty status - 2020-11-20

A small attempt to establish where Monty stands, where **I** stand, and what the major goals and  tasks ahead should/could be.

## What there is today
* a self-contained project at git.jeelabs.org/jcw/monty
* development uses PlatformIO (PIO) + Makefiles
* two kinds of test suites: C++ (in `tests/`) using Unity and Python scripts (in `verify/`)
* both can be run natively and on several µC boards
* C++ tests on µC targets depend on PIO's clever `test` functionality
* Python tests use some trickery for µC boards: upload .mpy file to fixed spot in RAM, and then reset the µC to run it
* several architectures have been tested, with the main focus on native-mac/-linux, stm32, and (less complete) esp8266 + esp32

### Notes
* these notes apply to the v0.95 release tag
* the main `lib/monty/` area has 16 source files with a total of ≈ 6100 lines of code (this excludes the arch-specific parts)
* this is not using a 100% strict TDD approach: tests are not always written first and code coverage is not 100% (more like 80+ right now)
* the directory layout is the result of trying to shoehorn all the different platforms and build variants into a single project - it's OK, but not great (e.g. having a `lib/config/` area just so other modules can find `config.h`)

## Functionality
* memory management, using garbage collection, designed for a (fixed) small-objects area and a (compacting) vector area
* a fairly complete interpreter for MicroPython bytecode (some gaps remain, e.g. keyword args)
* an extensive set of data structure primitives to match Python's needs (working, but slow: lookups are linear scans, for example)
* Python runtime stacks are implemented as movable and resizable vectors, one for each "generator object" (i.e. instantiated coro)
* there is a data structure format for compiled bytecode, but it's still in flux


### Loose ends
* a few Python tests can give output diffs, due to small timing differences, so test runs are not always reported as 100% passing
* an earlier version (v0.8?) of Monty had some builds for F103 boards with ENJ28J60 Ethernet hardware, using LwIP and ENC28J60 code from external projects - at one point it all worked, with basic network TCP sessions - all polled - this code broke due to a major Monty API rewrite
* very few "standard" Python runtime functions have been implemented - just enough to support testing, i.e. almost no Python string/math/io functions yet
* no benchmarks or performance optimizations have been performed, only code size is being watched so far - the current linear key search is definitely going to be atrociously slow, compared to hashing and other more practical techniques
* there _was_ some early documentation, but it's no longer accurate enough - new docs will need to be written, for design + development, and for installation + use

### The good parts
* memory management works great, even with plenty of room for improved algorithms and optimizations
* the VM is working exactly as intended: no nesting ever - there are no non-local jumps, the stack is always cleaned up via a return
* a "generator object" is equivalent to a Python stack, nested regular function expand (and potentially reduce) the stack of their caller, which should be quite efficient
* C++ virtual members plus templates create a powerful mix, which very compact code (both source and binary) and shoudl also lead to excellent performance
* the modularity of the code is quite good, but it's starting to become more difficult to keep that up
* the datatype hierarchy, although not optimized, reuses a lot of its own code - i.e. a `set` is a list with lookup functionality added, a `dict` is a set with a place to also store the associated value, the `str` type extends the `bytes` type, and byte arrays of various widths share a lot of common code
* coroutines and tasks just fell into place, once growable stacks and function calls worked properly - this leads to major reductions in complexity
* it looks like total flash and RAM memory use can be kept considerably lower than in MicroPython, making this system usable on more limited µC's (64k flash + 8k RAM might become a lower bound, although it obviously depends on use)

### The weak parts
* the main trouble-spot is dealing with intertwined C++/Python logic: e.g. `list()` can take a generator as argument, which _might_ be Python code - this means that the C code creating the list needs a way to "run" such Python bytecode, and it can't call (i.e. re-enter) the VM to accomplish this - the solution requires dealing with what are essentially continuations in C++ - a tough (and hard to debug) challenge
* this ugly beast rears its head in many places, and also makes blocking I/O quite tricky - but the whole point of Monty is to "get this right" (in the same way Go did) and to sidestep all the "async/await creep" problems which MicroPython (and CPython) are creating

### Open-ended issues
* module loading should be re-designed in such a way that (hopefully) a compiled Python module will be able to _really_ run out of flash
* ideally, there should be a way to build and load C++ modules without re-flashing the entire system - either out of flash (but saved there separately, as files of some kind, perhaps), or out of RAM
* some concurrency / synchronisation primitives will no doubt be needed, this will be a big task all by itself

## My take on this

The monty project has been on hold for a few months, due to external reasons. Because of this, it has unfortunately lost some momentum, but it has also allowed me to reflect on where Monty stands and what the bigger picture is / should be / could be. In no particular order:

1. This is a seriously interesting and attractive approach. It offers radical simplification opportunities, compared to existing high-level language VM designs, IMO. Simpler == more flexible & robust & general.

1. Async/await is an abomination, which somehow has crept into the Python world. All the headaches of threading are coming back in another disguise. The resulting high-level code is bound to be un-writable, un-readable, and un-manageable.

1. Monty already proves that Go-like concurrency is possible with very little complexity. Some major pain-points remain, so the jury is still out as to whether the final hurdles can indeed keep it that simple.

1. It's not really unexpected, but this project is likely to become much larger than originally intended before it can be put to practical use. Even just getting all the basic and obvious runtime support in there is a lot of work.

1. There have been two or three fairly substantial rewrites of some parts of Monty so far. This can be painful, as it occasionally breaks everything. I expect there to be at least one more such major change needed and coming ...

1. The expected change involves restructuring all of Monty to become more modular. Ideally, a small core (_kernel?_) should be managing resources, and loading all the remaining functionality as some kind of modules (unrelated to Python modules). This makes much more sense than grafting a C/C++ module loading system onto the system later on, since all of Monty is C/C++ anyway.

## What's next?
* go through all of Monty's code again, to get back on track
* fill in more gaps in the above summary - it's just a first write-up
* explore modularity and run-time linking / loading in a separate project
* identify the "Minimum Viable Core". i.e. what is the minimum functionality needed in the core to load & launch everything else from
* take a good look at the unsolved continuation / resume aspect of Monty - this _has to be_ resolved for Monty to become of any use
* once the core modularity is in place, all the different parts of Monty can be identified, built, and tested (hopefully at least partly in isolation): VM, data structures, runtime library support for Python, and a plethora of drivers (e.g. file systems, networking, varioues peripherals, attached devices)

### Minimum Viable Core

This is the code which gets control on power-up (including resuming after standby). For power consumption reasons, it must do the absolute minimum to get going and dispatch to the appropriate "main" code:

* standard C++ init, i.e. `.data` + `.bss` setup, and calling C++ static constructors
* establish power-up reason
* load/init additional driver(s), if not currently present
* dispatch to the proper application logic

Once running, the core becomes the "kernel" which manages resources and modules, and loads/inits new modules on-demand.

Module loading  
: This can be as simple as linking in all modules at once, with a simple dispatch call vector. At the other end of the range would be a dynamic loading mechanism, to add new modules at run time. A module-based system is infinitely extensible, in that the first module loaded can load and prepare everything else (similar to `main.py` in µPy). There is nothing novel about this, even a set of C++ classes or functions compiled into a single firmware image is modular (albeit somewhat rigid).

Memory management  
: The kernel should manage all memory, i.e. object and vector allocations, and garbage collections.

Resources management  
: The kernel should manage resources, regardless of their type, not just memory. E.g. file descriptions, network sessions, 

Locking primitives  
: Basic locking should be a kernel responsibility, to be able to control access to resources shared between different modules.

Complexity  
: The "Minimum Viable" aspect is key: whatever is in the kernel is harder to replace/fix (requires a full re-flash) and its API is harder to change (as it affects every module). Ideally (IMO), the kernel need not even be limited to being used for a Monty VM. It's a tiny core to give structure to the rest of the system (with Monty as major use case).

Q: How do modules perform kernel requests?  
: Could use ARM's "`svc <N>`" opcode, which is geared towards context switching (i.e. saving registers, optionally switching stacks). Alternately, a straight function call to a pre-defined address could be used - this would be more efficient, and could be vectorised using a C++ object V-table. Some thoughts, in no particular order:

Q: How are modules loaded?  
: If flash-based, i.e. already in the memory space, then it's just a matter of calling their init routine. If the module comes from a file system or a network connection, then the module can be placed in RAM. See the next item for the idea of placing them in the memory manager's vector space.

Q: How do modules call each other?  
: There are two options: through the kernel, or directly. Direct calls can be much more efficient. Perhaps modules can be "pre-linked" at load time, so that all references are resolved _once_. In this case, modules can only call functions which are already in the core or in a previously-loaded module. This is how Forth works (it cannot refer to undefined words). For flexibility, the "cornerstone" approach of Mecrips could be used: treat the loaded modules as a LIFO stack, and allow popping off multiple entries to reclaim memory. Forth is extremely modular, yet adds no extra performance overhead. When loaded in RAM, the code could be saved in special vectors stacked at the bottom end of vector space.

Q: Can multiple module instances exist?  
: Preferably not. As in Python, a module can only be instantiated once. This allows pre-linking of the data/bss sections, otherwise a dedicated register needs to be reserved (R9 or R12), which just moves the problem to how to set/restore that register. Modules which have _no_ data/bss at all could support multiple instances, though.
